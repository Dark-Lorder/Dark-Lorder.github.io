---
title: Docker容器简介
date: 2022-09-02 00:00:00
categories: Docker
tags:
- Docker
---

<!-- more -->

## 什么是 Docker

**Docker** 最初是 `dotCloud` 公司创始人 [Solomon Hykes](https://github.com/shykes) 在法国期间发起的一个公司内部项目，它是基于 `dotCloud` 公司多年云服务技术的一次革新，并于 [2013 年 3 月以 Apache 2.0 授权协议开源](https://en.wikipedia.org/wiki/Docker_(software))，主要项目代码在 [GitHub](https://github.com/moby/moby) 上进行维护。`Docker` 项目后来还加入了 Linux 基金会，并成立推动 [开放容器联盟（OCI）](https://opencontainers.org/)。

**Docker** 自开源后受到广泛的关注和讨论，至今其 [GitHub 项目](https://github.com/moby/moby) 已经超过 5 万 7 千个星标和一万多个 `fork`。甚至由于 `Docker` 项目的火爆，在 `2013` 年底，[dotCloud 公司决定改名为 Docker](https://www.docker.com/blog/dotcloud-is-becoming-docker-inc/)。`Docker` 最初是在 `Ubuntu 12.04` 上开发实现的；`Red Hat` 则从 `RHEL 6.5` 开始对 `Docker` 进行支持；`Google` 也在其 `PaaS` 产品中广泛应用 `Docker`。

**Docker** 使用 `Google` 公司推出的 [Go 语言](https://golang.google.cn/) 进行开发实现，基于 `Linux` 内核的 [cgroup](https://zh.wikipedia.org/wiki/Cgroups)，[namespace](https://en.wikipedia.org/wiki/Linux_namespaces)，以及 [OverlayFS](https://docs.docker.com/storage/storagedriver/overlayfs-driver/) 类的 [Union FS](https://en.wikipedia.org/wiki/Union_mount) 等技术，对进程进行封装隔离，属于 [操作系统层面的虚拟化技术](https://en.wikipedia.org/wiki/Operating-system-level_virtualization)。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 [LXC](https://linuxcontainers.org/lxc/introduction/)，从 `0.7` 版本以后开始去除 `LXC`，转而使用自行开发的 [libcontainer](https://github.com/docker/libcontainer)，从 `1.11` 版本开始，则进一步演进为使用 [runC](https://github.com/opencontainers/runc) 和 [containerd](https://github.com/containerd/containerd)。

<img src="https://img.darklorder.com/img/202308011722747.png"/>

Docker 架构

> `runc` 是一个 Linux 命令行工具，用于根据 [OCI容器运行时规范](https://github.com/opencontainers/runtime-spec) 创建和运行容器。

> `containerd` 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。

**Docker** 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 `Docker` 技术比虚拟机技术更为轻便、快捷。

下面的图片比较了 **Docker** 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。

<img src="https://img.darklorder.com/img/202308011725697.png"/>

传统虚拟化

<img src="https://img.darklorder.com/img/202308011725945.png"/>

Docker


## 为什么要用 Docker


作为一种新兴的虚拟化方式，`Docker` 跟传统的虚拟化方式相比具有众多的优势。

**更高效的利用系统资源**

由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，`Docker` 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。

**更快速的启动时间**

传统的虚拟机技术启动应用服务往往需要数分钟，而 `Docker` 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。

**一致的运行环境**

开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 `Docker` 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 _「这段代码在我机器上没问题啊」_ 这类问题。

**持续交付和部署**

对开发和运维（[DevOps](https://zh.wikipedia.org/wiki/DevOps)）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。

使用 `Docker` 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 [Dockerfile]() 来进行镜像构建，并结合 [持续集成(Continuous Integration)](https://en.wikipedia.org/wiki/Continuous_integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 [持续部署(Continuous Delivery/Deployment)](https://en.wikipedia.org/wiki/Continuous_delivery) 系统进行自动部署。

而且使用 [`Dockerfile`](https://yeasy.gitbook.io/docker_practice/image/build) 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。

**更轻松的迁移**

由于 `Docker` 确保了执行环境的一致性，使得应用的迁移更加容易。`Docker` 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。

**更轻松的维护和扩展**

`Docker` 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，`Docker` 团队同各个开源项目团队一起维护了一大批高质量的 [官方镜像](https://hub.docker.com/search/?type=image&image_filter=official)，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。

**对比传统虚拟机总结**

| 特性       | 容器               | 虚拟机      |
| ---------- | ------------------ | ----------- |
| 启动       | 秒级               | 分钟级      |
| 硬盘使用   | 一般为 `MB`        | 一般为 `GB` |
| 性能       | 接近原生           | 弱于        |
| 系统支持量 | 单机支持上千个容器 | 一般几十个  |


## 什么是容器

容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。

开发人员在自己笔记本上创建并测试好的容器，无需任何修改就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。Docker是容器的一种，还有其他容器，比如 CoreOS 的 rkt。

容器有效的将单个操作系统的资源划分到孤立的组中，以便更好的在孤立的组之间平衡有冲突的资源使用需求。

其实容器本身并不是一个特别新的技术，早在2000年就已经有了，当时是用来在chroot环境(隔离mount namespac的工具)中做进程隔离（使用namespac和cgroups）

容器的本质，一句话解释，就是一组受到资源限制，彼此间相互隔离的进程。实现起来也并不复杂，隔离所用到的技术都是由linux内核本身提供的（所以说目前绝大部分的容器都是必须要跑在linux里面的）。其中`namespace`用来做访问隔离（每个容器进程都有自己独立的进程空间，看不到其他进程），`cgroups`用来做资源限制（cpu、内存、存储、网络的使用限制）。

总的来说容器就是一种基于操作系统能力的隔离技术，这和虚拟化技术不可同日而语。

## 容器技术

分层构建（Layered Construction）、联合挂载（Union Mounting）和写时复制（Copy-on-Write）是三种 Linux 文件系统的特性，它们在容器技术中广泛应用。

- 分层构建：分层构建是指将一个文件系统划分为多个层次，每个层次只包含文件系统的一部分。这种分层构建的优点是可以重用已有的文件系统层次，提高了构建效率。在容器中，分层构建使得容器只需要记录自己的变更，从而避免了重复存储文件系统的问题。

- 联合挂载：联合挂载是指将多个文件系统联合成一个虚拟文件系统。在联合挂载的过程中，只有最上层的文件系统是可写的，其余文件系统只读。在容器中，联合挂载使得容器可以使用主机上的一些文件系统，从而避免了容器中需要存储相同的文件系统的问题。

- 写时复制：写时复制是指当一个进程试图修改一个文件时，会先将这个文件复制到一个新的位置，然后在新的位置上进行修改，从而避免了原始文件的修改。在容器中，写时复制可以使得容器只需要记录自己的变更，从而避免了对主机上原始文件的修改。

这三种特性在容器技术中被广泛应用，使得容器可以更高效地运行，同时也降低了容器与主机之间的耦合度。



## 深入剖析


### 初出茅庐

**PaaS项目被大家接纳的一个主要原因**

- 它提供了一种名叫“应用托管”的能力。 
- 租一批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，用脚本或者手工的方式在这些机器上部署应用。

> 缺点：部署过程难免会碰到云端虚拟机和本地环境不一致的问题。

**当年PaaS开源项目最佳方案**

- Cloud Foundry 项目
- 核心组件 一套应用的打包和分发机制

> 为每种主流编程语音都定义了一种打包格式,把应用的可执行文件和启动脚本打进一个压缩包内,上传到云端的存储中
通过调度器选择一个可以运行这个应用的虚拟机,然后通知这个机器上的Agent把应用压缩包下载下来启动。

**PaaS项目最核心的能力**

- 运行应用的隔离环境
- 或者说“沙盒”
- 就是所谓的“容器”

> 由于需要在一个虚拟机上启动很多个来自不同用户的应用,会调用操作系统的Cgroups和Namespace机制为每一个应用单独创建一个称作"沙盒"的隔离环境,然后在"沙盒"中启动这些应用程序。


### 崭露头角

**Dcoker项目能取得高关注度的原因**

- 解决了应用打包和发布这一困扰运维人员多年的技术难题
- 第一次把一个纯后端技术的概念,通过非常友好的设计,交到了最广大的开发者群体手里

**Docker公司为什么一定要发布Swarm项目**

- Docker项目从发布之初就全面发力,从技术,社区,商业,市场全方位争取到的开发者群体,实际上是为此后吸引整个生态到自家"PaaS"上的一个铺垫.
- 只不过这时,PaaS的定义已经全然不是Docker公司描述的那个样子,而是变成了一套以Docker容器为技术核心,以Docker容器为技术核心,以Docker镜像为打包标准的,全新的容器化思路
- 这正是Docker项目从一开始悉心运作容器化理念和经营整个Docker生态的主要目的
- 而Swarm项目正式接下来承接Docker公司所有这些努力的关键所在

**Docker在短时间内迅速崛起的三个重要原因**

- Docker镜像通过技术手段解决了PaaS的根本性问题
- Docker容器同开发者之间有着与生俱来的关系
- PaaS概念已经深入人心的完美时机


### 群雄并起

**Docker和CoreOS停止合作**

- 根本原因是Docker公司对Docker项目定位的不满足,想让Docker项目提供更多的平台层能力,即向PaaS项目进化
- 这显然与CoreOS公司的核心产品和战略发生了冲突

**Swarm项目的亮点**

- 完全使用Docker项目原本的容器管理API来完成集群管理的

**什么是编排**

- 主要是指用户如何通过某些或者配置来完成一组虚拟机以及关联资源的定义,配置,创建,删除等工作,然后由平台按照这些指定的逻辑来完成的过程

**Fig项目(后来的compose)**

- Fig在开发者面前第一次提出了"容器编排的概念"
- 容器和容器之间的关联关系,会由Fig交给Docker的Link功能通过写入Host文件的方式进行配置
- Fig被收购之后改名为Compose,他成为Docker公司目前为止第二大受欢迎的项目

**Docker公司收购的项目**

- Fig --> 编排
- SockerPlane --> 容器网络
- Flocker --> 容器存储（EMC公司收购）
- Tutum --> Docker集群图形化管理界面和提供云服务

**Mesos**

- Messos作为Berkeley主导的大数据套件之一,是大数据火热时最受欢迎的资源管理项目
- 发布Marathon实现了应用托管和负载均衡的PaaS功能
- Messos拥有超大规模集群的管理经验


### 尘埃落定

**容器编排领域的两个压力**

- Swarm擅长的是跟Docker生态的无缝集成
- Messos擅长的则是大规模集群的调度与管理
- Kubernetes借用Borg和Omega系统的内部特性

**基于Kubernetes的api和扩展接口的二次创新**

- 目前热度极高的微服务治理项目Istio
- 被广泛采用的有状态应用部署框架Operator
- 还有像Rook这样的开源创业项目,它通过Kubernetes的可扩展接口,把Ceph这样的重量级产品封装成了简单易用的容器存储插件

**编排落下帷幕**

- 2017年10月,Docker公司出人意料的宣布,将在自己的主打产品Docker企业版中内置Kubernetes项目
- 这标志着持续了进两年之久的"编排之争"至此落下帷幕

**Kubernetes成功的必然性**

- Docker公司最后是将开源项目和商业产品紧密绑定,打造一个极端封闭的技术生态
- 这其实违背了Docker项目与开发者保持密切关系的初衷
- 而Kubernetes社区正是以一种更加温和的方式,承接了Docker项目的未尽事业
- 即:以开发者为核心,构建一个相对民主和开放的容器生态


### 从进程说开去


**容器技术的几个事实**

-   容器技术的兴起起源于PaaS技术的普及
-   Docker公司发布的Docker项目具有里程碑式的意义
-   Docker项目通过"容器镜像",解决了应用打包这个根本性难题

**什么是容器**

-   容器就是一种沙盒技术,把你的应用"装起来",让其能够方便的搬来搬去

**进程**

-   一旦程序被执行起来,它就从磁盘上的二进制文件,
-   变成了计算机内存中的数据,寄存器里的值,堆栈中的指令,被打开的文件,以及各种设备的状态信息的一个集合.
-   像这样一个程序运行起来后的计算机执行环境的总和,就是进程

**进程的动态表现**

-   进程的静态表现就是程序,平时都安安静静的待在磁盘上
-   一旦运行起来,它就变成了计算机里的数据和状态的总和,这就是它的动态表现

**容器的核心功能**

-   通过约束和修改进程的动态表现,为期创造出一个"边界"

**容器的特性**

-   容器内的第一个进程的PID是1,其实是对被隔离的应用的进程空间做了手脚,
-   使得这些进程只能看到重新计算过的进程编号,比如PID=1,可实际上,
-   他们在宿主机的操作系统里,就是一个普通的进程

**容器名称空间**Namespace

-   Mount 挂载文件系统
-   UTS 主机名和域名
-   IPC 进程间通信
-   Network 网络
-   User 用户
-   PID 进程ID

**Docker并不是"轻量级"虚拟化技术**

-   跟真实存在的虚拟机不同,在使用Docker时,并没有一个真正的"Docker容器"运行在宿主机里面
-   Docker项目帮助用户启动的,还是原来的应用进程,只不过在创建这些进程的时候,
-   Docker为他们加上了各种各样的Namespace参数,
-   这时这些进程就会觉得自己是各PID Namespace里的第一号进程
-   只能看到各自Mount Namespace里挂载的目录和文件,只能访问到各自Network Namespace里的网路设备
-   仿佛在一个个"容器"里面,与世隔绝



### 隔离与限制


**传统虚拟机和Docker架构图**

<img src="https://img.darklorder.com/img/202308011842921.png"/>

-   对比图中Docker和应用同级别并且在靠边的位置
-   用户在容器里的应用进程,跟宿主机上的其他进程一样,都由宿主机操作系统统一管理
-   只不过这些被隔离的进程拥有额外设置过的Namespace参数
-   Docker在这里扮演的更多是旁路是的辅助和管理工作

**KVM虚拟机和容器的性能**

-   一个运行CentOS的KVM虚拟机在不做优化的情况下,虚拟机自己就要占用100-200MB内存
-   用户应用会被宿主机操作系统拦截和处理,损耗性能
-   容器化的应用依然是宿主机的一个进程,不存在虚拟化带来的性能损耗
-   使用Namespace作为隔离手段的容器并不需要单独的Guest OS,容器额外资源占用几乎不存在
-   "敏捷"和"高性能"是容器对比虚拟机的最大优势

**容器的隔离不彻底**

-   宿主机上的多个容器之间使用的还是同一个宿主机的操作系统内核
-   很多资源和对象不能被Namespace化,比如时间

**Cgroups资源限制**

-   blkio 为块设备设定I/O限制,一般用于磁盘等设置
-   cpuset 为进程分配单独的CPU核和对应的内存节点
-   memory 为进程设定内存使用的限制

**容器是单进程模型**

-   容器的本质就是一个进程,用户的应用进程实际上就是容器里的PID=1的进程
-   也是其他后续的所有进程的父进程
-   在一个容器中,只能实现找到一个公共的PID=1的程序来充当两个不同应用的父进程
-   这就是为什么很多人会使用systemd或者supervisord这样的软件来替代应用本身作为容器的启动进程

> 一个正在运行的 Docker 容器，其实就是一个启用了多个
Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。

**容器编排与容器生命周期**

-   容器本身的设计是希望容器和应用能够同生命周期
-   否则一旦出现容器是正常运行的,但是应用早就挂了的情况
-   在容器编排处理起来就很麻烦了

**Cgroups不完善的地方/proc文件系统**

-   Linux下的/proc目录存储是记录当前内核运行状态的一系列特殊文件
-   用户能通过这些文件,查看系统以及当前正在运行的进程的信息,
-   比如CPU使用,内存占用等,这些信息是top命令的主要信息来源
-   如果你在容器中执行top指令,就会发现它显示的是宿主机的CPU和内存数据,并不是当前容器的数据
-   因为/proc文件系统并不知道用户通过Cgroups给这个容器做了什么资源限制
-   即/proc文件系统并不了解Cgroup限制的存在
-   生产环境中必须修正这个问题,否则应用程序在容器里读取到的CPU核数,可用内存等信息都是宿主机上的数据
-   会给应用的运行带来非常大的风险和困惑,这是容器化相较于虚拟机不尽人意的地方


### 深入理解容器镜像

**Docker项目为待创建的用户进程做了以下事情**

-  启用Linux Namespace配置
-  设置指定的Cgroups参数
-  切换进程的跟目录(Change Root)

**注意**

-   rootfs只是一个操作系统所包含的文件,配置和目录,并不包括操作系统内核
-   在Linux操作系统中,这两部分是分开存放的
-   操作系统只有在开机启动时才会加载执行指定版本的内核镜像
-   rootfs只包括了操作系统的"躯壳",并没有包括操作系统的"灵魂"

**容器操作系统的"灵魂"**

-   同一台机器上的所有容器,都共享宿主机操作系统的内核
-   容器内的与内核相关的内核参数,内核模块,和内核的直接交互都是"全局变量",牵一发而动全身

**容器的一致性**

-   无论在本地,云端,还是在一台任何地方的的机器上
-   用户只需要解压打包好的容器镜像,那么这个应用运行所需要的完整的执行环境就被重现出来了
-   深入到操作系统级别的运行环境一致性,打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟

**联合文件系统(UnionFS)**

<img src="https://img.darklorder.com/img/202308011850015.png"/>

**第一层,只读层**  
他是这个容器的rootf最下面的五层,对应的正是ubuntu:latest镜像的五层  
可以看到它们的挂载方式都是只读的(ro+wh即readonly+whiteout)

**第二层,可读写层**  
它是容器rootfs最上面的一层,挂载方式为rw,即read write  
在没有写入文件之前,这个目录是空的.而且一旦在容器里面做了写操作,  
你的修改就会以增量的方式出现在这个层中  
删除文件时,AuFS会在可读写层创建一个whiteout文件,把只读层里的文件遮挡起来

**第三部分,init层**  
它是一个以"-init"结尾的层,夹在只读层和读写层之间  
init层是Docker项目单独生成的一个内部层,专门用来存放/etc/hosts, /etc/resolv.conf等信息  
需要这样一层的原因是,这些文件本来属于只读层的Ubuntu镜像的一部分  
但是用户往往需要在容器启动时就写入一些指定的值比如hostname,所以就需要在读写层对他们进行修改  
可以,这些修改往往只对当前的容器有效,我们并不希望执行docker commit时,  
把这些信息连同可读写层一起提交掉,所以docker的做法是,在修改了这些文件之后,  
以一个单独的层挂载了出来,用户执行docker commit只会提交可读写层,所以是不包含这些内容的

**分层镜像的设计好处**

-   以Docker镜像为核心,将不同技术人员紧密的联系在了一起
-   容器镜像是增量式的,每次镜像拉取,推送的内容,比完整操作系统要小得多
-   镜像发布之后,在全世界的任何地方下载这个镜像,可以完全复制镜像制作者当时的环境


### 重新认识Docker容器

**Docker exec的原理**

-   一个进程的Namespace信息在宿主机上是确确实实存在的,并且是以一个文件的方式存在
-   一个进程,可以选择加入到某个进程已有的Namespace中,从而达到"进入这个进程所在容器的目的"

**Docker commit原理**

-   实际上就是在容器运行起来后,把最上层的"可读写层",加上原先容器镜像的只读层
-   打包成了一个新的镜像.并且只读层在宿主机是共享的,不会占用额外的空间
-   由于使用了联合文件系统,你在容器里镜像rootfs所做的任何修改,
-   都会被操作系统复制到这个读写层,然后再修改,这就是所谓的Copy-on-Write
-   Init层的存在,就是为了避免执行docker commit时,
-   把Docker自己对/etc/hosts等文件的修改,也一起提交掉

**容器的volume**

docker run -v /test ...

-   Docker默认会在宿主机上创建一个临时目录/var/lib/docker/volumes/\[VOLUME\_ID\]/\_data
-   然后把它挂载到容器的/test目录上

docker run -v /home:/test ...

-   Docker直接把宿主机的/home目录挂载到容器的/test目录上

Docker是如何将宿主机目录挂载到容器的

-   只需要在容器的rootfs准备好之后,在执行chroot之前,把Volume指定的宿主机目录(比如/home目录)
-   挂载到指定的容器目录(比如/test目录)在宿主机上对应的目录(即/var/lib/docker/aufs/mnt/\[可读写层ID/test\])
-   这个Volume的挂载工作就完成了
-   由于执行这个挂载操作时,容器进程已经创建了,意味着此时Mount Namespace已经开启
-   所以挂载事件只在这个容器中可见,宿主机上看不到这个挂载点,保证了容器的隔离性不会被Volume打破

注意:

-   这里的"容器进程",是Docker创建的一个容器初始化进程(dockerinit),而不是应用进程(ENTRYPOINT+CMD)
-   dockerinit会负责完成根目录的准备,挂载设备和目录,配置hostname等一系列需要在容器内进行的初始化操作
-   最后它通过execv()系统调用,让应用进程取代自己,成为容器里的PID=1的进程

**挂载机制**

-   Docker中的挂载,使用的是Linux的绑定挂载(Bind Mount)机制
-   主要作用是运行你将一个目录或者文件,而不是整个设备,挂载到一个指定的目录上
-   原挂载点的内容则会被隐藏起来且不受影响
-   Bind Mount实际上是一个inode替换的过程

**Bind Mount的本质**

<img src="https://img.darklorder.com/img/202308011904273.png"/>

-   mount --bind /home /test 会将/home 挂载到/test上
-   实际上相当于/test的dentry,重定向到了/home的inode
-   当我们修改/test目录时,实际上就是修改的是/home目录的inode
-   这就是为何一旦执行umount命令,/test目录原先的内容就会恢复

**/test目录挂载在容器的可读写层,会不会被docker commit提交掉呢**

-   docker commit是发生在宿主机空间的
-   Mount Namespace的隔离作用,宿主机并不知道这个绑定挂载的存在
-   在宿主机看来,容器中可读写层的/test目录(/var/lib/docker/aufs/mnt/\[可读写层ID\]/test)始终是空的
-   由于Docker一开始还是要创建这个/test目录作为挂载点,执行完docker commit之后
-   新镜像中,会多出来一个空的/test目录,因为新建目录操作不是挂载操作,Mount Namespace不能起到"障眼法"的作用


### 谈谈Kubernetes的本质

**一个正在运行的Linux容器**

-  一组联合挂载在/var/lib/docker/aufs/mnt上的rootfs,也就是"容器镜像",容器的静态视图
-  一个由Namespace+Cgroup构成的隔离环境,这一部分称为"容器运行时",容器的动态视图

> 真正承载着容器信息进行传递的,是容器镜像,而不是容器运行时
0
**Kubernetes的由来**

-   核心特性都基于Borg/Omega系统的设计与经验
-   在开源社区落地过程中,修复了很多当年遗留在Borg体系中的缺陷和问题

**架构图**

<img src="https://img.darklorder.com/img/202308011905905.png"/>

和原型项目Borg非常类似,都由Master和Node两种节点组成,分别对应着控制节点和计算节点

控制节点,Master节点

-   负责API服务的kube-apiserver
-   负责调度的kube-scheduler
-   负责容器编排的kube-controller-manager
-   整个集群的持久化数据,由kube-apiserver处理后保存在Etcd中

计算节点,Node节点

-   kubelet主要负责和容器运行时打交道
-   而这个交互依赖的是CRI(Container Runtime Interface)的远程调用接口
-   这个接口定义了容器运行时的各项核心操作,比如启动一个容器所需要的所有参数
-   不需要关心是什么容器运行时,用到的什么基础
-   只要这个容器能够运行标准的容器镜像,他就可以通过实现CRI接入到Kubernetes项目当中

**容器运行时**

-   例如Docker项目,一般通过OCI这个容器运行时规范通底层的Linux操作系统进行交互
-   即:把CRI请求翻译成对Linux操作系统的调用(操作Linux Namespace和Cgroups等)

**kubelet**

-   kubelet还通过gRPC协议同一个叫做Device Plugin的插件进行交互
-   这个插件是Kubernetes项目用来管理GPU等宿主机物理机设备的主要组件
-   也是基于kubernetes项目进行机器学习,高性能作业支持等工作必须关注的功能
-   调用网络插件和存储插件为容器配置网络和持久化存储
-   这两个插件和kubelet交互的接口,分别是CNI(Container Networking Interface)和CSI(Container Storage Interface)

**Borg项目对Kubernetes的指导作用**

-   体现在Master节点之上
-   虽然在Master实现的细节上和Borg有所不同
-   但是出发点却高度一致:即如何编排,管理,调用用户提交的作业
-   将Docker仅仅作为最底层的一个容器运行时实现
-   着重解决的问题:运行在大规模集群中的各种任务之间,实际上存在着各种各样的关系
-   处理这些关系,才是作业编排和管理系统最困难的地方

**Kubernetes项目最主要的设计思想**

从宏观的角度,以统一的方式来定义任务之间的各种关系,并且为将来支持更多种类的关系留有余地

**紧密关系的应用**

-   这些应用之间需要非常频繁的交互和访问,或者直接通过本地文件系统进行信息交换
-   在常规环境下,这些应用往往会直接部署在同一台机器上,通过localhost通信,通过本地磁盘交换文件
-   但在Kubernetes项目中,这些容器会被划分为一个Pod
-   Pod里的容器共享同一个Network Namespace ,同一数据卷,从而达到高效交换信息的目的

**类似Web应用和数据库之间的访问关系**

-   Kubernetes提供了一种叫做Service的服务
-   给Pod绑定一个Service服务,而Service服务声明的IP地址等信息是终生不变的
-   这个Service服务的主要作用,就是作为Pod的代理入口
-   从而代替Pod对外暴露一个固定的网络地址

**Secret对象**

-   其实是保存在Etcd里的键值对数据
-   可以把Credential信息以Secret的方式存在Etcd里
-   Kubernetes就会在你指定的Pod启动时,自动把Secret里的数据以Volume的方式挂载刀片容器里

**Kubernetes的推崇做法**

-   通过一个"编排对象",比如PodmJob,CronJob等,来描述你试图管理的应用
-   再为它定义一些"服务对象",比如Service,Secret, HPA等.这些对象会负责具体的平台级功能





**参考资料**
[Docker-从入门到实践](
https://yeasy.gitbook.io/docker_practice/)
[极客时间-深入剖析Kubernetes](
https://time.geekbang.org/column/intro/116)
[kwen94-博客](
https://kkwen.cn/index.php/category/kubernetes/)
